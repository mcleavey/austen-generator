{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jane Austen Generator\n",
    "In honor of Valentine's Day, a Jane Austen generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses PyTorch, torchtext, and the fastai library: https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Text files to several Jane Austen novels. Dividing them here into train & validation:\n",
    "JANE_PATH='./language_model/austen/'\n",
    "\n",
    "TRN_PATH = 'train/'\n",
    "VAL_PATH = 'test/'\n",
    "\n",
    "JANE_TRN = f'{JANE_PATH}{TRN_PATH}'\n",
    "JANE_VAL = f'{JANE_PATH}{VAL_PATH}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friendship.txt',\n",
       " 'input.txt',\n",
       " 'letters.txt',\n",
       " 'mansfield.txt',\n",
       " 'northanger.txt',\n",
       " 'persuasion.txt',\n",
       " 'pride.txt',\n",
       " 'sense.txt',\n",
       " 'susan.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_files = !ls {JANE_TRN} \n",
    "trn_files   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "an example line in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thought of his cruel conduct towards Mrs Smith, she could hardly bear',\n",
       " 'the sight of his present smiles and mildness, or the sound of his',\n",
       " 'artificial good sentiments.',\n",
       " '',\n",
       " 'She meant to avoid any such alteration of manners as might provoke a']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = !cat {JANE_TRN}{trn_files[5]}\n",
    "line[7000:7005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724695\r\n"
     ]
    }
   ],
   "source": [
    "!find {JANE_TRN} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160356\r\n"
     ]
    }
   ],
   "source": [
    "!find {JANE_VAL} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Parameters: `bs` (batch size) and `bptt`(how many words processed at a time in each row of the mini-batch)\n",
    "\n",
    "Making bptt higher will increase time and memory requirements, but will improve the model's ability to handle long sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs=32; bptt=120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters: `embedding_size` (embedding vector size), `nhidden` (number of hidden activations per layer), `nlayers` (number of layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 300; nhidden = 500; nlayers = 3       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimization_function = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the language model. Right now, the word embedding matrices are random. When we train the model,\n",
    "they will take on meaningful values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(JANE_PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump TEXT so that we will be able to access the same word tokenization later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(TEXT, open(f'{JANE_PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 223\n",
      "Unique Word Tokens: 4932\n",
      "Sentences in Training Set: 860595\n"
     ]
    }
   ],
   "source": [
    "print(f'Batches: {len(md.trn_dl)}\\nUnique Word Tokens: {md.nt}\\nSentences in Training Set: {len(md.trn_ds[0].text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dropout values may need tuning. Others should be fine as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(optimization_function, embedding_size, nhidden, nlayers,\n",
    "               dropouti=0.07, dropout=0.07, wdrop=0.15, dropoute=0.025, dropouth=0.055)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583d650dd145449e84534295a3af3a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.645441   5.478835  \n",
      "    1      5.041722   4.861283                              \n",
      "    2      4.778134   4.709964                              \n",
      "    3      4.55439    4.475187                              \n",
      "    4      4.326685   4.326903                              \n",
      "    5      4.198656   4.264                                 \n",
      "    6      4.142878   4.243988                              \n",
      "    7      4.150627   4.20584                               \n",
      "    8      4.030343   4.135465                              \n",
      "    9      3.930853   4.083008                              \n",
      "    10     3.843416   4.049754                              \n",
      "    11     3.77174    4.027615                              \n",
      "    12     3.732222   4.015193                              \n",
      "    13     3.702667   4.004896                              \n",
      "    14     3.675034   4.005867                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0058665]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('jane_0_enc')       # Save the newly determined word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.load_encoder('jane_0_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdae010d4bd4848bc52b9dab426e509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.683675   4.006124  \n",
      "    1      3.777827   4.024555                              \n",
      "    2      3.726166   4.011042                              \n",
      "    3      3.664113   4.004571                              \n",
      "    4      3.60846    3.98568                               \n",
      "    5      3.546603   3.987119                              \n",
      "    6      3.519214   3.979949                              \n",
      "    7      3.461685   3.983063                              \n",
      "    8      3.419532   3.980531                              \n",
      "    9      3.381018   3.986598                              \n",
      "    10     3.34568    3.99754                               \n",
      "    11     3.296165   4.00575                               \n",
      "    12     3.278288   4.007909                              \n",
      "    13     3.247021   4.00965                               \n",
      "    14     3.221758   4.017701                              \n",
      "    15     3.190748   4.019388                              \n",
      "    16     3.19121    4.018678                              \n",
      "    17     3.173135   4.02499                               \n",
      "    18     3.193425   4.01785                               \n",
      "    19     3.183979   4.022858                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.022858]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('jane_1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.load_encoder('jane_1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Story Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAKE_JANE = f'{JANE_PATH}/fake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" Why , good Morning Mr. Darcy ! \" she exclaimed . \\n \" Hello my dearest Elinor \" , he said . \\n'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=learner.model\n",
    "ss= '\"Why, good Morning Mr. Darcy!\" she exclaimed. \\n\"Hello my dearest Elinor\", he said.\\n'\n",
    "num_words = 250\n",
    "s = [spacy_tok(ss)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" With the first moment of hearing,\n",
      "      “That is a very great thing to you, as I am now, to be sure, and that I should not be able in any way that way.”\n",
      "      “Oh! My dear,” replied her ladyship,\n",
      "      “You have not a doubt, fanny, that I should be so glad to have you go, and that I am sure you would not have gone so far.” And with a look of voice, she added, in an air,\n",
      "      “That you should be able to go to town.”\n",
      "      “Yes; but you must not think me so ill-used as you can do, and that I can not bear it; and I am sure you have no reason to suppose it possible that you should not have the smallest objection to your own. But I am sure you would not be able to think it worth your doing very much, I assure.”\n",
      "      “Yes; I have not a doubt of your being so very agreeable.” Fanny was too much oppressed by the idea of being so much more, and that it would be so. She could only say that it had not occurred to her that the subject had been so long delayed. The first time which had passed on her side...\n"
     ]
    }
   ],
   "source": [
    "beam = 2\n",
    "more_random = True\n",
    "\n",
    "print_lead = \"\"\n",
    "cap = True\n",
    "skip_space = True\n",
    "\n",
    "print(print_lead, end = '')\n",
    "    \n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "res,*_ = m(t)\n",
    "m[0].bs=bs\n",
    "\n",
    "out = \"\"\n",
    "for i in range(num_words):\n",
    "    [ps, n] =res[-1].topk(beam)\n",
    "    if more_random or i<beam or i%4 == 0:        \n",
    "        w = n[np.random.randint(0, beam)]      # Choose a word out of the most likely 'beam' options (to add variety)\n",
    "    else:\n",
    "        w = n[0]                               # Choose the single most likely word\n",
    "    while w.data[0] == 0:\n",
    "        w = n[np.random.randint(0, beam)]\n",
    "    wstr = TEXT.vocab.itos[w.data[0]]\n",
    "    out = out + wstr + \" \"\n",
    "    # Here I add some minor text formatting. The following doesn't change anything substantive from the model, but reconnects\n",
    "    # things like ca n't, which the tokenizer pulled apart. It also notes to capitalize letters after . ? ! \"\n",
    "    if wstr=='i': wstr='I'\n",
    "    if wstr=='nt': wstr = 'not'\n",
    "    if cap:\n",
    "        wstr = wstr.capitalize()\n",
    "    if wstr in ['.', '?', '!', '“']: \n",
    "        cap=True\n",
    "    elif wstr not in ['”', '\"']:\n",
    "        cap=False\n",
    "    if skip_space or wstr in ['.', ',', ';', \"'\", '”', \"n't\", \"n’t\", \"’ll\", \"'ll\", \"’s\", \"’ve\", \"'ve\", \"’d\", \"’re\", \"’m\", \"'s\", \"'d\", \"?\", \"!\", \"'re\", \"'m\"]:\n",
    "        print(wstr, end='')\n",
    "        skip_space = False\n",
    "    elif wstr=='“':\n",
    "        print(f'\\n      {wstr}', end='')\n",
    "        skip_space = True\n",
    "    elif wstr in ['to-', '-', 'good-']:\n",
    "        print(wstr, end='')\n",
    "        skip_space = True\n",
    "    elif wstr=='\"':\n",
    "        pass\n",
    "    else:\n",
    "        print(f' {wstr}', end='')\n",
    "              \n",
    "    res,*_ = m(w[0].unsqueeze(0))\n",
    "print('...')\n",
    "i=0\n",
    "text_file = open(f'{FAKE_JANE}{i}.txt', \"a\")\n",
    "text_file.write(out)\n",
    "text_file.write('\\n\\n')\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Favorite results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a good-natured, good-humoured young man, and a great deal more to the purpose than the rest. I have been thinking of him, but he has not been so much pleased with his character, as to be a man of good sense. I am not sorry for the idea. I am not sorry to see you again. I am sure he has been so much more attached to me, and that I have no doubt of the very circumstance that is ever to be made of. I have had the pleasure of receiving a letter from me. I have had no doubt that I should not have been in my life. I have been very kind and very kind in the world to have you so much in love with you. You have been a very good kind of woman, but as I am not in the least fatigued by the world. I am sure you have been so much more attached to her, and that I can hardly help thinking it all. I am not afraid that the whole party are in town, and that we are all very much in the habit. We have been very much in town; and I have no reason for writing, and that I am very glad you will be able in the same time to see you..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a good-humoured, handsome, handsome girl, and not like a man of fortune. I have no idea that I should be able to do any thing in the world.”<br>\n",
    "     &nbsp;&nbsp;&nbsp; “I am afraid you will be very happy.”<br>\n",
    "     &nbsp;&nbsp;&nbsp; “Yes; but you know, that I have no reason to fear that I should be so happy as to make the most of it, and that you will be able to make the greatest part.” Fanny could not help smiling. She could only say, that she had no longer a thought of her.<br>\n",
    "     &nbsp;&nbsp;&nbsp; “You have no idea of your being so very much in your power, I assure you.” She then added :<br>\n",
    "     &nbsp;&nbsp;&nbsp; “I have not a notion I can have a great idea to be in the country.” Fanny could not help smiling. She was sure she had not seen it; and, after a moment's recollection, said to elizabeth :<br>\n",
    "     &nbsp;&nbsp;&nbsp; “You are mistaken. I am not afraid of seeing him. I am sure you will not have the least idea of the matter. I have no doubt that I can not be so happy as you can do.” She then went away, but she could only say that he had been in the room; but he had not seen her before,...<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the first moment of hearing,<br>\n",
    "      &nbsp;&nbsp;&nbsp;“That is a very great thing to you, as I am now, to be sure, and that I should not be able in any way that way.”<br>\n",
    "      &nbsp;&nbsp;&nbsp;“Oh! My dear,” replied her ladyship,<br>\n",
    "      &nbsp;&nbsp;&nbsp;“You have not a doubt, fanny, that I should be so glad to have you go, and that I am sure you would not have gone so far.” And with a look of voice, she added, in an air,<br>\n",
    "      &nbsp;&nbsp;&nbsp;“That you should be able to go to town.”<br>\n",
    "      &nbsp;&nbsp;&nbsp;“Yes; but you must not think me so ill-used as you can do, and that I can not bear it; and I am sure you have no reason to suppose it possible that you should not have the smallest objection to your own. But I am sure you would not be able to think it worth your doing very much, I assure.”<br>\n",
    "      &nbsp;&nbsp;&nbsp;“Yes; I have not a doubt of your being so very agreeable.” Fanny was too much oppressed by the idea of being so much more, and that it would be so. She could only say that it had not occurred to her that the subject had been so long delayed. The first time which had passed on her side..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Is it Jane?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create text files with fake Jane Austen. Then we'll build a model to classify whether input text is fake or genuine.  Finally, we'll loop through, generate 100 potential text generations, and then output the one that has the highest score from the classifier.  (This is to capture the sense that sometimes the text generator outputs a plausible paragraph, and sometimes it's a mess.  I'd like to have it output the best of 100 tries.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenum = 0\n",
    "num_outputs = 20\n",
    "beam = 2\n",
    "more_random = True\n",
    "    \n",
    "m[0].bs=1\n",
    "m.eval()\n",
    "m.reset()\n",
    "res,*_ = m(t)\n",
    "m[0].bs=bs\n",
    "for j in range(20):\n",
    "    out = \"\"\n",
    "    for i in range(num_words):\n",
    "        [ps, n] =res[-1].topk(beam)\n",
    "        if more_random or i<beam or i%4 == 0:        \n",
    "            w = n[np.random.randint(0, beam)]      # Choose a word out of the most likely 'beam' options (to add variety)\n",
    "        else:\n",
    "            w = n[0]                               # Choose the single most likely word\n",
    "        while w.data[0] == 0:\n",
    "            w = n[np.random.randint(0, beam)]\n",
    "        wstr = TEXT.vocab.itos[w.data[0]]\n",
    "        out = out + wstr + \" \"\n",
    "              \n",
    "        res,*_ = m(w[0].unsqueeze(0))\n",
    "\n",
    "    text_file = open(f'{FAKE_JANE}{filenum}.txt', \"a\")\n",
    "    text_file.write(out)\n",
    "    text_file.write('\\n\\n')\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{JANE_PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
